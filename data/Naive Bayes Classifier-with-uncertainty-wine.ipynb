{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.optim as optim\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.distributions import constraints\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(1)\n",
    "pyro.enable_validation(True)\n",
    "pyro.clear_param_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading datasets\n",
    "df = pd.read_csv('wine.data', header=None)\n",
    "X = df.iloc[:,1:]\n",
    "y = df.iloc[:,0].astype(int)\n",
    "y = y - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X):\n",
    "    # rejestrujemy zmienną do przestrzeni optymalizacji (store pyro)\n",
    "    mu_param = pyro.param(\"mu\", torch.zeros_like(naive_bayes.current_class_probs))\n",
    "    # ograniczamy wartości do nieujemnych\n",
    "    sigma_param = pyro.param(\"sigma\", torch.ones_like(naive_bayes.current_class_probs), constraint=constraints.positive)\n",
    "    params = pyro.distributions.Normal(loc=mu_param, scale=sigma_param).to_event(1)\n",
    "    with pyro.plate(\"map\", len(X)):\n",
    "        pyro.sample(\"probs\", params, obs=X)\n",
    "\n",
    "def guide(X):\n",
    "    # rejestrujemy zmienną do przestrzeni optymalizacji (store pyro)\n",
    "    mu_param = pyro.param(\"mu\", torch.zeros_like(naive_bayes.current_class_probs))\n",
    "    # ograniczamy wartości do nieujemnych\n",
    "    sigma_param = pyro.param(\"sigma\", torch.ones_like(naive_bayes.current_class_probs), constraint=constraints.positive)\n",
    "    probs_prior = pyro.distributions.Normal(loc=mu_param, scale=sigma_param).to_event(1)\n",
    "    return pyro.sample(\"probs\", probs_prior, infer={'is_auxiliary': True})\n",
    "\n",
    "def train(X):\n",
    "    pyro.clear_param_store()\n",
    "    num_iterations=5000\n",
    "    optim = pyro.optim.Adam({\"lr\": 0.03})\n",
    "    svi = pyro.infer.SVI(model, guide, optim, loss=pyro.infer.Trace_ELBO(), num_samples=len(X))\n",
    "    losses = list()\n",
    "    t=tqdm(range(num_iterations))\n",
    "    for j in t:\n",
    "        loss = svi.step(X)\n",
    "        losses.append(loss)\n",
    "        t.set_postfix(loss=loss)\n",
    "    return (svi, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, threshold=0.8):\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        self.available_y = np.unique(y)\n",
    "        self.num_features = X.shape[1]\n",
    "        self._count_y_prob()\n",
    "        self.params_for_probs = list()\n",
    "        \n",
    "        for target in self.available_y:\n",
    "            self.X_current_class = torch.from_numpy(X[y==target])\n",
    "            self.current_class_probs = torch.from_numpy(np.random.randn(self.num_features))\n",
    "            train(self.X_current_class)\n",
    "            mu = pyro.param(\"mu\")\n",
    "            sigma = pyro.param(\"sigma\")\n",
    "            sigma2 = sigma*sigma # pyro uses std instead of var\n",
    "            self.params_for_probs.append(torch.stack([mu, sigma2], dim=0))\n",
    "            \n",
    "        for i in range(len(self.params_for_probs)):\n",
    "            self.params_for_probs[i] = self.params_for_probs[i].detach().numpy()\n",
    "            \n",
    "    def _count_y_prob(self):\n",
    "        total_quantity = len(self.y)\n",
    "        self.p_y = [np.count_nonzero(self.y == i) / total_quantity for i in self.available_y]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Returns -1 if classifier is not sure of prediciton.\"\"\"\n",
    "        predicted = list()\n",
    "        for i in range(len(X)):\n",
    "            predicted.append(self._predict_one_example(i, X[i, :]))\n",
    "        return np.asarray(predicted)\n",
    "\n",
    "    def _predict_one_example(self, i: int, x: np.ndarray):\n",
    "        certainity_for_ys = list()\n",
    "        for y in self.available_y:  # for every class\n",
    "            certainity_for_ys.append(self.p_y[y])\n",
    "            for i in range(len(x)):  # for every feature\n",
    "                certainity_for_ys[-1] *= self._p_xi_on_condition_y(i, y, x[i])\n",
    "        certainity_for_ys = self._normalize_values(certainity_for_ys)\n",
    "        if max(certainity_for_ys) > self.threshold:\n",
    "            return self.available_y[certainity_for_ys.index(max(certainity_for_ys))]\n",
    "        else:\n",
    "            print(\"I'm not sure.\")\n",
    "            return -1\n",
    "    \n",
    "    def _p_xi_on_condition_y(self, feature_index, y_index, x_i):\n",
    "        multiplier = 1 / np.sqrt(2 * np.pi * self.params_for_probs[y_index][1, feature_index])\n",
    "        exp = - (x_i - self.params_for_probs[y_index][0, feature_index]) ** 2 / (2 * self.params_for_probs[y_index][1, feature_index])\n",
    "        return multiplier * np.power(np.e, exp)\n",
    "    \n",
    "    def _normalize_values(self, v):\n",
    "        sum_of_values = sum(v)\n",
    "        out_vals = v / sum_of_values\n",
    "        return list(out_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes = NaiveBayesClassifier()\n",
    "# naive_bayes.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossval_research(data, target):\n",
    "    splitter = StratifiedKFold(n_splits=7, shuffle=True)\n",
    "    split_set_generator = splitter.split(data, target)\n",
    "\n",
    "    # trainning and testing\n",
    "    y_pred = list()\n",
    "    y_true = list()\n",
    "\n",
    "    #train_indices, test_indices = next(split_set_generator)\n",
    "    for train_indices, test_indices in split_set_generator:\n",
    "        X_train = data[train_indices]\n",
    "        Y_train = target[train_indices]\n",
    "        naive_bayes.fit(X_train, Y_train)\n",
    "        y_pred.extend(naive_bayes.predict(data[test_indices]))\n",
    "        y_true.extend(target[test_indices])\n",
    "\n",
    "    whole_ds_len = len(y_pred)\n",
    "    # removing examples that bayes is uncertain of\n",
    "    for i in range(len(y_pred)-1,0,-1):\n",
    "        if y_pred[i] == -1:\n",
    "            del y_pred[i]\n",
    "            del y_true[i]\n",
    "    removed_uncertain_len = len(y_pred)\n",
    "            \n",
    "    confusion = metrics.confusion_matrix(y_true, y_pred)\n",
    "    accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "    precision = metrics.precision_score(y_true, y_pred, average=None)\n",
    "    recall = metrics.recall_score(y_true, y_pred, average=None)\n",
    "    f1_score = metrics.f1_score(y_true, y_pred, average=None)\n",
    "    \n",
    "    print(\"Number of examples classified: {} of {}\".format(removed_uncertain_len, whole_ds_len))\n",
    "    print(\"It is {}%\".format(float(removed_uncertain_len)/whole_ds_len*100.0))\n",
    "\n",
    "    return {\"confusion\": confusion, \"accuracy\": accuracy, \"precision\": precision,\n",
    "            \"recall\": recall, \"f1_score\": f1_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be7bc24996c84e67b767a75705e2548c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b44c66ea4140179a227ddd5cd94140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc9e0939555a4065a98b703c0965722e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not sure.\n",
      "I'm not sure.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a2d1d732e84a0991d5d8ed358e4430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6a87d686ef4a4687dc2b140587d154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ebac6c5a064681b55f979a08f6ae74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not sure.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f93cc08f6aee49b5a1e55cbf142ce13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc12784a7a7843b5820b753cbcdb3c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86ddd7c7a05b419798e407504b5e5fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not sure.\n",
      "I'm not sure.\n",
      "I'm not sure.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea792431dc844a18b64cfc77c529e888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5e92cb78894f0abadd0cdc820befe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0eddd04345b4ab38d66470498b3161d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not sure.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20fdb71c74d84b978a9ef120e4133ec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c6d714b13d4467d9ca78af47b10a020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "424bbceac6a9467c88f41e8d6e114f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "905578b366c34f6f9579857e8c718b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5006050c715f4e7398c80642e223ee50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76c4fe7879b040ec9c0b383e56a10f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not sure.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35cd57d07294413eb84d7a61a13dc60c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97198fffcda04f1b9284b7f9643de053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_metrics = crossval_research(X.values, y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reasearch of model and guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.37447458e+01 2.01067797e+00 2.45559322e+00 1.70372881e+01\n",
      " 1.06338983e+02 2.84016949e+00 2.98237288e+00 2.90000000e-01\n",
      " 1.89932203e+00 5.52830508e+00 1.06203390e+00 3.15779661e+00\n",
      " 1.11571186e+03]\n",
      "[4.58192306e-01 6.82688763e-01 2.25232619e-01 2.52465123e+00\n",
      " 1.04095949e+01 3.36076522e-01 3.94110623e-01 6.94530691e-02\n",
      " 4.08601851e-01 1.22803157e+00 1.15491282e-01 3.54037572e-01\n",
      " 2.19635449e+02]\n"
     ]
    }
   ],
   "source": [
    "X_class_0 = X[y==0].values\n",
    "print(X_class_0.mean(0))\n",
    "print(X_class_0.std(0))\n",
    "\n",
    "means = torch.zeros_like(torch.from_numpy(X_class_0[0,:]))\n",
    "stds = torch.ones_like(torch.from_numpy(X_class_0[0,:]))\n",
    "\n",
    "X_class_0 = torch.from_numpy(X_class_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X):\n",
    "    # rejestrujemy zmienną do przestrzeni optymalizacji (store pyro)\n",
    "    mu_param = pyro.param(\"mu\", torch.zeros_like(means))\n",
    "    # ograniczamy wartości do nieujemnych\n",
    "    sigma_param = pyro.param(\"sigma\", torch.ones_like(stds), constraint=constraints.positive)\n",
    "    params = pyro.distributions.Normal(loc=mu_param, scale=sigma_param)\n",
    "    #with pyro.plate(\"map\", len(X)):\n",
    "    pyro.sample(\"probs\", params, obs=X)\n",
    "\n",
    "def guide(X):\n",
    "    # rejestrujemy zmienną do przestrzeni optymalizacji (store pyro)\n",
    "    mu_param = pyro.param(\"mu\", torch.zeros_like(means))\n",
    "    # ograniczamy wartości do nieujemnych\n",
    "    sigma_param = pyro.param(\"sigma\", torch.ones_like(stds), constraint=constraints.positive)\n",
    "    probs_prior = pyro.distributions.Normal(loc=mu_param, scale=sigma_param)\n",
    "    return pyro.sample(\"probs\", probs_prior, infer={'is_auxiliary': True})\n",
    "\n",
    "def train(X):\n",
    "    pyro.clear_param_store()\n",
    "    num_iterations=1000\n",
    "    optim = pyro.optim.Adam({\"lr\": 0.05})\n",
    "    svi = pyro.infer.SVI(model, guide, optim, loss=pyro.infer.Trace_ELBO(), num_samples=len(X))\n",
    "    losses = list()\n",
    "    t=tqdm(range(num_iterations))\n",
    "    for j in t:\n",
    "        loss = svi.step(X)\n",
    "        losses.append(loss)\n",
    "        t.set_postfix(loss=loss)\n",
    "    return (svi, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb5c56814988420294756a91437a3296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "at site \"probs\", invalid log_prob shape\n  Expected [], actual [59, 13]\n  Try one of the following fixes:\n  - enclose the batched tensor in a with plate(...): context\n  - .to_event(...) the distribution being sampled\n  - .permute() data dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-bbe2e652198c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msvi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_class_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-96de509283d0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pyro/infer/svi.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# get loss and compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mparam_capture\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_and_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         params = set(site[\"value\"].unconstrained()\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pyro/infer/trace_elbo.py\u001b[0m in \u001b[0;36mloss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;31m# grab a trace from the generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_traces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0mloss_particle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurrogate_loss_particle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_differentiable_loss_particle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_particle\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pyro/infer/elbo.py\u001b[0m in \u001b[0;36m_get_traces\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pyro/infer/trace_elbo.py\u001b[0m in \u001b[0;36m_get_trace\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \"\"\"\n\u001b[1;32m     51\u001b[0m         model_trace, guide_trace = get_importance_trace(\n\u001b[0;32m---> 52\u001b[0;31m             \"flat\", self.max_plate_nesting, model, guide, *args, **kwargs)\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_validation_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mcheck_if_enumerated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguide_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pyro/infer/enum.py\u001b[0m in \u001b[0;36mget_importance_trace\u001b[0;34m(graph_type, max_plate_nesting, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msite\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sample\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                 \u001b[0mcheck_site_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_plate_nesting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msite\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mguide_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sample\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pyro/util.py\u001b[0m in \u001b[0;36mcheck_site_shape\u001b[0;34m(site, max_plate_nesting)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;34m'- enclose the batched tensor in a with plate(...): context'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0;34m'- .to_event(...) the distribution being sampled'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 '- .permute() data dimensions']))\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# Check parallel dimensions on the left of max_plate_nesting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: at site \"probs\", invalid log_prob shape\n  Expected [], actual [59, 13]\n  Try one of the following fixes:\n  - enclose the batched tensor in a with plate(...): context\n  - .to_event(...) the distribution being sampled\n  - .permute() data dimensions"
     ]
    }
   ],
   "source": [
    "svi, losses = train(X_class_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro_mu = pyro.param(\"mu\")\n",
    "pyro_sigma = pyro.param(\"sigma\")\n",
    "data_mu = X_class_0.mean(0)\n",
    "data_sigma = X_class_0.std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.3745e+01, 2.0107e+00, 2.4556e+00, 1.7037e+01, 1.0634e+02, 2.8402e+00,\n",
      "        2.9824e+00, 2.9000e-01, 1.8993e+00, 5.5283e+00, 1.0620e+00, 3.1578e+00,\n",
      "        1.1157e+03], dtype=torch.float64)\n",
      "tensor([5.9885, 2.0107, 2.4556, 4.8188, 3.5172, 2.8402, 2.9824, 0.2900, 1.8993,\n",
      "        5.5283, 1.0620, 3.1578, 3.4797], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "tensor([-7.7562e+00, -4.4409e-16, -4.4409e-16, -1.2218e+01, -1.0282e+02,\n",
      "         8.8818e-16,  0.0000e+00, -1.1842e-07, -2.2204e-16,  3.5527e-15,\n",
      "         0.0000e+00,  0.0000e+00, -1.1122e+03], dtype=torch.float64,\n",
      "       grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor([4.6213e-01, 6.8855e-01, 2.2717e-01, 2.5463e+00, 1.0499e+01, 3.3896e-01,\n",
      "        3.9749e-01, 7.0049e-02, 4.1211e-01, 1.2386e+00, 1.1648e-01, 3.5708e-01,\n",
      "        2.2152e+02], dtype=torch.float64)\n",
      "tensor([ 8.5325,  0.6885,  0.2272, 13.0133, 30.8680,  0.3390,  0.3975,  0.0700,\n",
      "         0.4121,  1.2386,  0.1165,  0.3571, 32.3126], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([ 8.0704e+00,  0.0000e+00,  8.3267e-17,  1.0467e+01,  2.0369e+01,\n",
      "         0.0000e+00,  0.0000e+00,  4.9392e-09,  1.1102e-16,  2.2204e-16,\n",
      "        -5.5511e-17, -5.5511e-17, -1.8921e+02], dtype=torch.float64,\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(data_mu)\n",
    "print(pyro_mu)\n",
    "print(pyro_mu - data_mu)\n",
    "print()\n",
    "print(data_sigma)\n",
    "print(pyro_sigma)\n",
    "print(pyro_sigma - data_sigma)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
